{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429aa5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = \"/home/olel/Projects/productivity_robot_backend/train/emotion_classifier/train.csv\"\n",
    "VALID_CSV_PATH = \"/home/olel/Projects/productivity_robot_backend/train/emotion_classifier/validation.csv\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2895595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import csv as _csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21e70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        print(f\"[INFO] Loading dataset from {data_path}\")\n",
    "        self.classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "        # self.data_file = open(data_path, 'r')\n",
    "        # self.reader = _csv.reader(self.data_file, delimiter=',', quotechar='\"')\n",
    "        # next(self.reader)\n",
    "        # self.label = np.array([self.get_label_index(row[0]) for row in self.reader])\n",
    "        \n",
    "        self.data_file = open(data_path, 'r')\n",
    "        self.reader = _csv.reader(self.data_file, delimiter=',', quotechar='\"')\n",
    "        next(self.reader)\n",
    "\n",
    "        self.data = [row for row in self.reader]\n",
    "        np.random.shuffle(self.data)\n",
    "        self.label = np.array([self.get_label_index(row[0]) for row in self.data])\n",
    "        try:\n",
    "            self.data = np.array([list(map(float, row[1:])) for row in self.data], dtype=np.float32)\n",
    "        except ValueError as e:\n",
    "            print(f\"[ERROR] ValueError while converting data to float: {e}\")\n",
    "        finally:\n",
    "            print(f\"[INFO] Closing data file\")\n",
    "            print(f\"[DEBUG] Last row read: {self.data[-1]}, label: {self.label[-1]}, length of data: {len(self.data)}, length of label: {len(self.label)}\")\n",
    "            self.data_file.close()\n",
    "            self.reader = None\n",
    "            # self.data[-1]\n",
    "\n",
    "        # self.data = np.array([])\n",
    "        # self.label = np.array([])\n",
    "        # for row in self.reader:\n",
    "        #     index = int(len(self.data)*np.random.rand())\n",
    "        #     if type(row[0]) is not str or not row[0] in self.classes: \n",
    "        #         print(f\"[WARN] label_name is not str: {row[0]} ({type(row[0])}), maybe empty line or end of file? skipping...\")\n",
    "        #         continue\n",
    "        #     self.data = np.insert(self.data, index, np.array([float(x) for x in row[1:]]), axis=0) if len(self.data) > 0 else np.array([np.array([float(x) for x in row[1:]])])\n",
    "        #     self.label = np.insert(self.label, index, self.get_label_index(row[0]))\n",
    "        #     print(f\"[DEBUG] self.label shape: {self.label.shape}, self.data shape: {self.data.shape}, total samples: 26784 or 6599\", end='\\r')\n",
    "\n",
    "        # self.data = np.array([row for row in self.reader])\n",
    "        # print(f\"[INFO] Shuffling dataset\")\n",
    "        # np.random.shuffle(self.data)\n",
    "        print(self.label[:10])\n",
    "\n",
    "        # self.label = np.array([self.get_label_index(row[0]) for row in self.data])\n",
    "        # self.data = np.array([list(map(float, row[1:])) for row in self.data], dtype=np.float32)\n",
    "\n",
    "        print(f\"[INFO] Loaded {len(self.data)} samples from {data_path}\")\n",
    "        print(f\"[INFO] len of labels: {len(self.label)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "    def get_label_index(self, label_name):\n",
    "        try:\n",
    "            index = self.classes.index(label_name)\n",
    "        except ValueError:\n",
    "            print(f\"[ERROR] label_name '{label_name}' not found in classes {self.classes}\")\n",
    "        return self.classes.index(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5b8c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from /home/olel/Projects/productivity_robot_backend/train/emotion_classifier/train.csv\n",
      "[INFO] Closing data file\n",
      "[DEBUG] Last row read: [ 0.50400186  0.6909957  -0.12264685 ...  0.7118063   0.3888369\n",
      "  0.03782844], label: 3, length of data: 26783, length of label: 26783\n",
      "[4 4 0 3 5 2 2 6 0 3]\n",
      "[INFO] Loaded 26783 samples from /home/olel/Projects/productivity_robot_backend/train/emotion_classifier/train.csv\n",
      "[INFO] len of labels: 26783\n",
      "[INFO] Loading dataset from /home/olel/Projects/productivity_robot_backend/train/emotion_classifier/validation.csv\n",
      "[INFO] Closing data file\n",
      "[DEBUG] Last row read: [ 0.5172771   0.78088796 -0.1413979  ...  0.7201979   0.40283176\n",
      "  0.16438115], label: 2, length of data: 6598, length of label: 6598\n",
      "[2 5 6 5 3 4 4 6 3 3]\n",
      "[INFO] Loaded 6598 samples from /home/olel/Projects/productivity_robot_backend/train/emotion_classifier/validation.csv\n",
      "[INFO] len of labels: 6598\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EmotionDataset(data_path=TRAIN_CSV_PATH)\n",
    "valid_dataset = EmotionDataset(data_path=VALID_CSV_PATH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805ec68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_landmarks=478, num_features=3, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # After pooling twice, sequence length roughly reduces to num_landmarks / 4\n",
    "        reduced_len = num_landmarks // 4\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * reduced_len, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, 1434]\n",
    "        x = x.view(-1, self.num_landmarks, self.num_features)  # [B, 478, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, 478] for Conv1d (channels-first)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.flatten(1)  # flatten all except batch\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7f45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs, train_loader, valid_loader, loss_function, optimizer, device):\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = -1\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            if device.type == 'cuda':\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                if device.type == 'cuda':\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        print(f\"[INFO] Epoch {epoch}: Loss={epoch_loss:.4f}, Acc={epoch_acc:.4f}\")\n",
    "        torch.save(model.state_dict(), f\"emotion_classifier_epoch_{epoch}_{epoch_loss}.pth\")\n",
    "        print(f\"[INFO] Saved model checkpoint for epoch {epoch}\")\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "            \n",
    "    print(f\"[INFO] Best validation loss: {best_loss:.4f} at epoch {best_epoch}\")\n",
    "    # torch.save(model.state_dict(), f\"emotion_classifier_best_epoch_{best_epoch}_{best_loss}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14a4044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "model = EmotionClassifier()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"[INFO] Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c9ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch 0: Loss=1.6310, Acc=0.3950\n",
      "[INFO] Saved model checkpoint for epoch 0\n",
      "[INFO] Epoch 1: Loss=1.5527, Acc=0.3692\n",
      "[INFO] Saved model checkpoint for epoch 1\n",
      "[INFO] Epoch 2: Loss=1.5198, Acc=0.3851\n",
      "[INFO] Saved model checkpoint for epoch 2\n",
      "[INFO] Epoch 3: Loss=1.5084, Acc=0.4192\n",
      "[INFO] Saved model checkpoint for epoch 3\n",
      "[INFO] Epoch 4: Loss=1.4939, Acc=0.4263\n",
      "[INFO] Saved model checkpoint for epoch 4\n",
      "[INFO] Epoch 5: Loss=1.5536, Acc=0.3750\n",
      "[INFO] Saved model checkpoint for epoch 5\n",
      "[INFO] Epoch 6: Loss=1.5319, Acc=0.4268\n",
      "[INFO] Saved model checkpoint for epoch 6\n",
      "[INFO] Epoch 7: Loss=1.4929, Acc=0.4447\n",
      "[INFO] Saved model checkpoint for epoch 7\n",
      "[INFO] Epoch 8: Loss=1.4749, Acc=0.4542\n",
      "[INFO] Saved model checkpoint for epoch 8\n",
      "[INFO] Epoch 9: Loss=1.4842, Acc=0.4303\n",
      "[INFO] Saved model checkpoint for epoch 9\n",
      "[INFO] Epoch 10: Loss=1.5248, Acc=0.4397\n",
      "[INFO] Saved model checkpoint for epoch 10\n",
      "[INFO] Epoch 11: Loss=1.4469, Acc=0.4588\n",
      "[INFO] Saved model checkpoint for epoch 11\n",
      "[INFO] Epoch 12: Loss=1.4519, Acc=0.4459\n",
      "[INFO] Saved model checkpoint for epoch 12\n",
      "[INFO] Epoch 13: Loss=1.4565, Acc=0.4530\n",
      "[INFO] Saved model checkpoint for epoch 13\n",
      "[INFO] Epoch 14: Loss=1.4329, Acc=0.4636\n",
      "[INFO] Saved model checkpoint for epoch 14\n",
      "[INFO] Epoch 15: Loss=1.4686, Acc=0.4501\n",
      "[INFO] Saved model checkpoint for epoch 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, epochs, train_loader, valid_loader, loss_function, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(model, EPOCHS, train_loader=train_loader, valid_loader=valid_loader, loss_function=loss_function, optimizer=optimizer, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
